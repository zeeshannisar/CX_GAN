{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Step 1-Generate Normal Distribution from Infected Distribution with CycleGANs.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"evQ0kLNXSRn4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624119305739,"user_tz":-120,"elapsed":8872,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgB98M2R854pgSNoFHTc84UFb61VJp9lNw0sZiCmp0=s64","userId":"05353617243036990298"}},"outputId":"8eda4166-7aff-47d3-b556-dd3a2c8fc378"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RNvte7liJ8ZW"},"source":["!pip install tensorflow_addons"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4PEpA1N8pRCM","executionInfo":{"status":"ok","timestamp":1624121107086,"user_tz":-120,"elapsed":288,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgB98M2R854pgSNoFHTc84UFb61VJp9lNw0sZiCmp0=s64","userId":"05353617243036990298"}},"outputId":"7dbd6340-cd2d-4ff9-ae29-6ef16002844f"},"source":["import os\n","import datetime\n","import random\n","import warnings\n","import numpy as np\n","import sys\n","import matplotlib.pyplot as plt\n","\n","\n","os.chdir('/content/drive/MyDrive/GitHub Repositories')\n","baseDir = './CXGAN/Cascaded Model/Synthetic'\n","\n","normal = np.load(os.path.join(baseDir, 'dataset', 'Circle', '0', 'images.npy'), mmap_mode = 'r')[:]\n","infected = np.load(os.path.join(baseDir, 'dataset', 'Circle', '1', 'images.npy'), mmap_mode = 'r')[:]\n","print('Synthetic Data Class-0 : {}'.format(normal.shape))\n","print('Synthetic Data Class-1 : {}'.format(infected.shape))\n","\n","train_normal = normal[:490]\n","test_normal = normal[490:]\n","train_infected = infected[:490]\n","test_infected = infected[490:]\n","print('Train-0 : {} | Test-0: {}'.format(train_normal.shape, test_normal.shape))\n","print('Train-1 : {} | Test-1: {}'.format(train_infected.shape, test_infected.shape))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Synthetic Data Class-0 : (500, 128, 128, 1)\n","Synthetic Data Class-1 : (500, 128, 128, 1)\n","Train-0 : (490, 128, 128, 1) | Test-0: (10, 128, 128, 1)\n","Train-1 : (490, 128, 128, 1) | Test-1: (10, 128, 128, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jf_kYoDspaEM"},"source":["class ImageBuffer():\n","    \"\"\"This class implements an image buffer that stores previously generated images.\n","    This buffer enables us to update discriminators using a history of generated images\n","    rather than the ones produced by the latest generators.\n","    \"\"\"\n","\n","    def __init__(self, buffer_size):\n","        \"\"\"Initialize the ImagePool class\n","        Parameters:\n","            pool_size (int) -- the size of image buffer, if pool_size=0, no buffer will be created\n","        \"\"\"\n","        self.buffer_size = buffer_size\n","        if self.buffer_size > 0:  # create an empty pool\n","            self.num_imgs = 0\n","            self.images = []\n","\n","    def query(self, images):\n","        \"\"\"Return an image from the pool.\n","        Parameters:\n","            images: the latest generated images from the generator\n","        Returns images from the buffer.\n","        By 50/100, the buffer will return input images.\n","        By 50/100, the buffer will return images previously stored in the buffer,\n","        and insert the current images to the buffer.\n","        \"\"\"\n","        if self.buffer_size == 0:  # if the buffer size is 0, do nothing\n","            return images\n","        return_images = []\n","        for image in images:\n","            #image = torch.unsqueeze(image.data, 0)\n","            if self.num_imgs < self.buffer_size:   # if the buffer is not full; keep inserting current images to the buffer\n","                self.num_imgs = self.num_imgs + 1\n","                self.images.append(image)\n","                return_images.append(image)\n","            else:\n","                p = random.uniform(0, 1)\n","                if p > 0.5:  # by 50% chance, the buffer will return a previously stored image, and insert the current image into the buffer\n","                    random_id = random.randint(0, self.buffer_size - 1)  # randint is inclusive\n","                    tmp = self.images[random_id]\n","                    self.images[random_id] = image\n","                    return_images.append(tmp)\n","                else:       # by another 50% chance, the buffer will return the current image\n","                    return_images.append(image)\n","        return return_images"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ND6dHoFiOa_g"},"source":["**Generator with U-Net Architecture**                              \n","**Discriminator**                                                               \n","**Combined Network**"]},{"cell_type":"code","metadata":{"id":"vQcSx9OO3_AK"},"source":["import tensorflow as tf\n","import tensorflow_addons as tfa\n","\n","def padding(input, pad_top, pad_bottom, pad_left, pad_right, mode=\"REFLECT\"):\n","    if mode==\"CONSTANT\":\n","        return tf.keras.layers.Lambda(lambda x: tf.pad(x, [[0,0], [pad_top, pad_bottom], [pad_left, pad_right], [0,0]],\n","                                                       'CONSTANT'))(input)\n","    elif mode==\"REFLECT\":\n","        return tf.keras.layers.Lambda(lambda x: tf.pad(x, [[0,0], [pad_top, pad_bottom], [pad_left, pad_right], [0,0]],\n","                                                       'REFLECT'))(input)\n","    elif mode==\"SYMMETRIC\":\n","        return tf.keras.layers.Lambda(lambda x: tf.pad(x, [[0,0], [pad_top, pad_bottom], [pad_left, pad_right], [0,0]],\n","                                                       'SYMMETRIC'))(input)\n","\n","def normalization(input, mode=\"instance\", name=None):\n","    if mode == 'batch':\n","        return tf.keras.layers.BatchNormalization(name=name)(input)\n","    elif mode == 'instance':\n","        return tfa.layers.InstanceNormalization(axis=3, center=True, scale=True, name=name)(input)\n","    elif mode == 'layer':\n","        return tf.keras.layers.LayerNormalization(name=name)(input)\n","    elif mode == 'group':\n","        return tfa.layers.GroupNormalization()(input)\n","\n","def activation(input, mode='relu', name=None):\n","    if mode == 'relu':\n","        return tf.keras.layers.ReLU(name=name)(input)\n","    elif mode == 'leaky_relu':\n","        return tf.keras.layers.LeakyReLU(alpha=0.2, name=name)(input)\n","\n","def discriminator_loss(y_true, y_pred):\n","        return 0.5 * tf.keras.losses.mse(y_true, y_pred)\n","\n","\n","\n","class CycleGAN_model():\n","    def __init__(self, image_height, image_width, image_channels):\n","        # As suggested in paper, while optimizing D authors divide the objective by 2,\n","        # which slows down the rate at which D learns, relative to the rate of G\n","\n","        self.lambda_cycle = 10.0  # Cycle-consistency loss\n","        self.lambda_id = 0.5 * self.lambda_cycle  # Identity loss\n","\n","        self.optimizer = tf.keras.optimizers.Adam(0.0002)\n","\n","        # As suggested in paper Weights are initialized from a Gaussian distribution with mean 0 and std-dev 0.02.\n","        initializer = tf.keras.initializers.RandomNormal(mean=0, stddev=0.02)\n","\n","        image_height = image_height\n","        image_width = image_width\n","        image_channels = image_channels\n","\n","        image_shape = (image_height, image_width, image_channels)\n","        self.normalization_type = 'instance'\n","\n","        self.D_A = self.Discriminator(image_shape=image_shape, initializer=initializer, name='Discriminator_A')\n","        self.D_B = self.Discriminator(image_shape=image_shape, initializer=initializer, name='Discriminator_B')\n","        self.D_A.compile(loss=discriminator_loss, optimizer=self.optimizer, metrics=['accuracy'])\n","        self.D_B.compile(loss=discriminator_loss, optimizer=self.optimizer, metrics=['accuracy'])\n","\n","        self.disc_patch = (self.D_A.output_shape[1], self.D_A.output_shape[1], 1)\n","\n","        self.G_A2B = self.Generator(image_shape=image_shape, initializer=initializer, name='Generator_A2B')\n","        self.G_B2A = self.Generator(image_shape=image_shape, initializer=initializer, name='Generator_B2A')\n","\n","        # Input images from both domains\n","        image_A = tf.keras.layers.Input(shape=image_shape)\n","        image_B = tf.keras.layers.Input(shape=image_shape)\n","        # Translate images to the other domain\n","        fake_B = self.G_A2B(image_A)\n","        fake_A = self.G_B2A(image_B)\n","        # Reconstruct translated images back to original domain\n","        reconstr_A = self.G_B2A(fake_B)\n","        reconstr_B = self.G_A2B(fake_A)\n","        # Identity mapping of images\n","        image_A_id = self.G_B2A(image_A)\n","        image_B_id = self.G_A2B(image_B)\n","\n","        # For the combined model we will only train the generators\n","        self.D_A.trainable = False\n","        self.D_B.trainable = False\n","\n","        # Discriminators determines validity of translated images\n","        valid_A = self.D_A(fake_A)\n","        valid_B = self.D_B(fake_B)\n","\n","        # Combined model trains generators to fool discriminators\n","        self.combined = tf.keras.models.Model(inputs=[image_A, image_B],\n","                                         outputs=[valid_A, valid_B, reconstr_A, reconstr_B, image_A_id, image_B_id])\n","        self.combined.compile(loss=['mse', 'mse', 'mae', 'mae', 'mae', 'mae'],\n","                         loss_weights=[1, 1, self.lambda_cycle, self.lambda_cycle, self.lambda_id, self.lambda_id], optimizer=self.optimizer)\n","\n","    def num_resblocks(self, input, normalization_type, mode_activation, initializer, num_blocks):\n","        num_filters = input.get_shape()[-1]\n","        for i in range(num_blocks):\n","            output = self.residual_block(input, num_filters, normalization_type, mode_activation, initializer,\n","                                         name='resblock_{}'.format(i + 1))\n","            input = output\n","\n","        return output\n","\n","    def residual_block(self, input, num_filters, normalization_type, mode_activation, initializer, name=None):\n","        x = input\n","\n","        x = padding(x, pad_top=1, pad_bottom=1, pad_left=1, pad_right=1, mode=\"REFLECT\")\n","        x = tf.keras.layers.Conv2D(filters=num_filters, kernel_size=(3, 3), strides=(1, 1), padding='valid',\n","                                   use_bias=False,\n","                                   kernel_initializer=initializer, name='R256_conv1_{}'.format(name))(x)\n","        x = normalization(x, mode=normalization_type, name='R256_conv1_{}_instance'.format(name))\n","        x = activation(x, mode=mode_activation, name='R256_conv1_{}_relu'.format(name))\n","\n","        x = padding(x, pad_top=1, pad_bottom=1, pad_left=1, pad_right=1, mode=\"REFLECT\")\n","        x = tf.keras.layers.Conv2D(filters=num_filters, kernel_size=(3, 3), strides=(1, 1), padding='valid',\n","                                   use_bias=False,\n","                                   kernel_initializer=initializer, name='R256_conv2_{}'.format(name))(x)\n","        x = normalization(x, mode=normalization_type, name='R256_conv2_{}_instance'.format(name))\n","\n","        return activation(tf.keras.layers.Add()([input, x]), mode=mode_activation, name='added_{}_relu'.format(name))\n","\n","    def Generator(self, image_shape, initializer, name='Generator'):\n","        # reflection padding was used in the Cycle-GAN implementation to reduce the artifacts\n","        # c7s1_64 denotes a 7*7 Convolution-InstanceNorm-Relu layer with 64 filters and stride 1.\n","        # d128 denotes 3*3 Convolution-InstanceNorm-Relu layer with 128 filters and stride 2.\n","        # d256 denotes 3*3 Convolution-InstanceNorm-Relu layer with 256 filters and stride 2.\n","        # R256 denotes a residual block that contains two 3*3 Convolutionsal layers with the same number of filters (256) on both layers\n","        # c7s1_3 denotes a 7*7 Convolution-InstanceNorm-Relu layer with RGB filters and stride 1.\n","\n","        input = tf.keras.Input(shape=image_shape)\n","        pad = padding(input, pad_top=3, pad_bottom=3, pad_left=3, pad_right=3, mode=\"REFLECT\")\n","        c7s1_64 = tf.keras.layers.Conv2D(filters=64, kernel_size=(7, 7), strides=(1, 1), padding='valid',\n","                                         use_bias=False, kernel_initializer=initializer, name='c7s1_64')(pad)\n","        c7s1_64 = normalization(c7s1_64, mode=self.normalization_type, name='c7s1_64_instance')\n","        c7s1_64 = activation(c7s1_64, mode='relu', name='c7s1_64_relu')\n","\n","        d_128 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='same',\n","                                       use_bias=False, kernel_initializer=initializer, name='d128')(c7s1_64)\n","        d_128 = normalization(d_128, mode=self.normalization_type, name='d128_instance')\n","        d_128 = activation(d_128, mode='relu', name='d128_relu')\n","\n","        d_256 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(2, 2), padding='same',\n","                                       use_bias=False, kernel_initializer=initializer, name='d256')(d_128)\n","        d_256 = normalization(d_256, mode=self.normalization_type, name='d256_instance')\n","        d_256 = activation(d_256, mode='relu', name='d256_relu')\n","\n","        # residual block (6 blocks for image_size = (128, 128, 3) and 9 blocks for greater image sizes)\n","        if image_shape[0] <= 128:\n","            R_256 = self.num_resblocks(d_256, self.normalization_type, 'relu', initializer, num_blocks=6)\n","        else:\n","            R_256 = self.num_resblocks(d_256, self.normalization_type, 'relu', initializer, num_blocks=9)\n","\n","            # fractional-strided convolutions\n","        u_128 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(3, 3), strides=(2, 2), padding='same',\n","                                                use_bias=False, kernel_initializer=initializer, name='u64')(R_256)\n","        u_128 = normalization(u_128, mode=self.normalization_type, name='u64_instance')\n","        u_128 = activation(u_128, mode='relu', name='u64_relu')\n","\n","        u_64 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=(2, 2), padding='same',\n","                                               use_bias=False, kernel_initializer=initializer, name='u128')(u_128)\n","        u_64 = normalization(u_64, mode=self.normalization_type, name='u128_instance')\n","        u_64 = activation(u_64, mode='relu', name='u128_relu')\n","\n","        # Note: The paper said that ReLU and _norm were used here but actually tanh was used and no normalization at\n","        # the original CycleGAN-pytorch implementation at https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n","        pad = padding(u_64, pad_top=3, pad_bottom=3, pad_left=3, pad_right=3, mode=\"REFLECT\")\n","        c7s1_3 = tf.keras.layers.Conv2D(filters=1, kernel_size=(7, 7), strides=(1, 1), padding='valid',\n","                                        activation='tanh', kernel_initializer=initializer, name='c7s1-3')(pad)\n","\n","        output = c7s1_3\n","\n","        return tf.keras.Model(inputs=input, outputs=output, name=name)\n","\n","    def Discriminator(self, image_shape, initializer, name=None):\n","\n","        input = tf.keras.Input(shape=image_shape)\n","\n","        pad = tf.keras.layers.ZeroPadding2D(padding=(1, 1))(input)\n","        c64 = tf.keras.layers.Conv2D(filters=64, kernel_size=(4, 4), strides=(2, 2), padding='same',\n","                                     kernel_initializer=initializer, name='c64')(pad)\n","        c64 = activation(c64, mode='leaky_relu', name='c64_leakyrelu')\n","\n","        pad = tf.keras.layers.ZeroPadding2D(padding=(1, 1))(c64)\n","        c128 = tf.keras.layers.Conv2D(filters=128, kernel_size=(4, 4), strides=(2, 2), padding='same',\n","                                      use_bias=False, kernel_initializer=initializer, name='c128')(pad)\n","        c128 = normalization(c128, mode=self.normalization_type, name='c128_instance')\n","        c128 = activation(c128, mode='leaky_relu', name='c128_leakyrelu')\n","\n","        pad = tf.keras.layers.ZeroPadding2D(padding=(1, 1))(c128)\n","        c256 = tf.keras.layers.Conv2D(filters=256, kernel_size=(4, 4), strides=(2, 2), padding='same',\n","                                      use_bias=False, kernel_initializer=initializer, name='c256')(pad)\n","        c256 = normalization(c256, mode=self.normalization_type, name='c256_instance')\n","        c256 = activation(c256, mode='leaky_relu', name='c256_leakyrelu')\n","\n","        pad = tf.keras.layers.ZeroPadding2D(padding=(1, 1))(c256)\n","        c512 = tf.keras.layers.Conv2D(filters=512, kernel_size=(4, 4), strides=(1, 1), padding='same',\n","                                      use_bias=False, kernel_initializer=initializer, name='c512')(pad)\n","        c512 = normalization(c512, mode=self.normalization_type, name='c512_instance')\n","        c512 = activation(c512, mode='leaky_relu', name='c512_leakyrelu')\n","\n","        output = tf.keras.layers.Conv2D(filters=1, kernel_size=(4, 4), strides=(1, 1), padding='same',\n","                                        kernel_initializer=initializer, name='output')(c512)\n","\n","        return tf.keras.Model(inputs=input, outputs=output)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cdh521v44XOx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1624122082257,"user_tz":-120,"elapsed":3630,"user":{"displayName":"ZEESHAN NISAR","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgB98M2R854pgSNoFHTc84UFb61VJp9lNw0sZiCmp0=s64","userId":"05353617243036990298"}},"outputId":"512dfffc-4a98-41db-d1be-310ce4293ce2"},"source":["import os\n","import numpy as np\n","import matplotlib\n","matplotlib.use('agg')\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","import random\n","\n","\n","image_width = 128\n","image_height = 128\n","image_channels = 1\n","\n","\n","model = CycleGAN_model(image_height=image_height, image_width=image_width, image_channels=image_channels)\n","print('********************* Generator Architecture*********************')\n","print(model.G_A2B.summary())\n","print('********************* Discriminator Architecture*********************')\n","print(model.D_A.summary())\n","\n","def sample_images(epoch, batch_i, img_A, img_B):\n","    saveDir = baseDir+'/results'\n","    os.makedirs(saveDir, exist_ok=True)\n","    r, c = 2, 3\n","\n","    # Translate images to the other domain\n","    fake_B = model.G_A2B.predict(img_A)\n","    fake_A = model.G_B2A.predict(img_B)\n","    # Translate back to original domain\n","    reconstr_A = model.G_B2A.predict(fake_B)\n","    reconstr_B = model.G_A2B.predict(fake_A)\n","\n","    img_A = img_A[0, :][np.newaxis, ...]\n","    img_B = img_B[0, :][np.newaxis, ...]\n","    fake_A = fake_A[0, :][np.newaxis, ...]\n","    fake_B = fake_B[0, :][np.newaxis, ...]\n","    reconstr_A = reconstr_A[0, :][np.newaxis, ...]\n","    reconstr_B = reconstr_B[0, :][np.newaxis, ...]\n","\n","    gen_imgs = np.concatenate([img_A, fake_B, reconstr_A, img_B, fake_A, reconstr_B])\n","\n","    # Rescale images 0 - 1\n","    gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","    titles = ['Original', 'Translated', 'Reconstructed']\n","    fig, axs = plt.subplots(r, c)\n","    cnt = 0\n","    for i in range(r):\n","        for j in range(c):\n","            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n","            axs[i, j].set_title(titles[j])\n","            axs[i, j].axis('off')\n","            cnt += 1\n","    fig.savefig(saveDir + '/result' + str(epoch) + '_' + str(batch_i) + '.png')\n","    plt.close()\n","\n","def learning_rate_decay(epoch, same_lr, reach_zero):\n","    return (1.0 - max(0, epoch + 1 - same_lr) / float(reach_zero))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["********************* Generator Architecture*********************\n","Model: \"Generator_A2B\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_54 (InputLayer)           [(None, 128, 128, 1) 0                                            \n","__________________________________________________________________________________________________\n","lambda_224 (Lambda)             (None, 134, 134, 1)  0           input_54[0][0]                   \n","__________________________________________________________________________________________________\n","c7s1_64 (Conv2D)                (None, 128, 128, 64) 3136        lambda_224[0][0]                 \n","__________________________________________________________________________________________________\n","c7s1_64_instance (InstanceNorma (None, 128, 128, 64) 128         c7s1_64[0][0]                    \n","__________________________________________________________________________________________________\n","c7s1_64_relu (ReLU)             (None, 128, 128, 64) 0           c7s1_64_instance[0][0]           \n","__________________________________________________________________________________________________\n","d128 (Conv2D)                   (None, 64, 64, 128)  73728       c7s1_64_relu[0][0]               \n","__________________________________________________________________________________________________\n","d128_instance (InstanceNormaliz (None, 64, 64, 128)  256         d128[0][0]                       \n","__________________________________________________________________________________________________\n","d128_relu (ReLU)                (None, 64, 64, 128)  0           d128_instance[0][0]              \n","__________________________________________________________________________________________________\n","d256 (Conv2D)                   (None, 32, 32, 256)  294912      d128_relu[0][0]                  \n","__________________________________________________________________________________________________\n","d256_instance (InstanceNormaliz (None, 32, 32, 256)  512         d256[0][0]                       \n","__________________________________________________________________________________________________\n","d256_relu (ReLU)                (None, 32, 32, 256)  0           d256_instance[0][0]              \n","__________________________________________________________________________________________________\n","lambda_225 (Lambda)             (None, 34, 34, 256)  0           d256_relu[0][0]                  \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_1 (Conv2D)  (None, 32, 32, 256)  589824      lambda_225[0][0]                 \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_1_instance  (None, 32, 32, 256)  512         R256_conv1_resblock_1[0][0]      \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_1_relu (ReL (None, 32, 32, 256)  0           R256_conv1_resblock_1_instance[0]\n","__________________________________________________________________________________________________\n","lambda_226 (Lambda)             (None, 34, 34, 256)  0           R256_conv1_resblock_1_relu[0][0] \n","__________________________________________________________________________________________________\n","R256_conv2_resblock_1 (Conv2D)  (None, 32, 32, 256)  589824      lambda_226[0][0]                 \n","__________________________________________________________________________________________________\n","R256_conv2_resblock_1_instance  (None, 32, 32, 256)  512         R256_conv2_resblock_1[0][0]      \n","__________________________________________________________________________________________________\n","add_96 (Add)                    (None, 32, 32, 256)  0           d256_relu[0][0]                  \n","                                                                 R256_conv2_resblock_1_instance[0]\n","__________________________________________________________________________________________________\n","added_resblock_1_relu (ReLU)    (None, 32, 32, 256)  0           add_96[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_227 (Lambda)             (None, 34, 34, 256)  0           added_resblock_1_relu[0][0]      \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_2 (Conv2D)  (None, 32, 32, 256)  589824      lambda_227[0][0]                 \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_2_instance  (None, 32, 32, 256)  512         R256_conv1_resblock_2[0][0]      \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_2_relu (ReL (None, 32, 32, 256)  0           R256_conv1_resblock_2_instance[0]\n","__________________________________________________________________________________________________\n","lambda_228 (Lambda)             (None, 34, 34, 256)  0           R256_conv1_resblock_2_relu[0][0] \n","__________________________________________________________________________________________________\n","R256_conv2_resblock_2 (Conv2D)  (None, 32, 32, 256)  589824      lambda_228[0][0]                 \n","__________________________________________________________________________________________________\n","R256_conv2_resblock_2_instance  (None, 32, 32, 256)  512         R256_conv2_resblock_2[0][0]      \n","__________________________________________________________________________________________________\n","add_97 (Add)                    (None, 32, 32, 256)  0           added_resblock_1_relu[0][0]      \n","                                                                 R256_conv2_resblock_2_instance[0]\n","__________________________________________________________________________________________________\n","added_resblock_2_relu (ReLU)    (None, 32, 32, 256)  0           add_97[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_229 (Lambda)             (None, 34, 34, 256)  0           added_resblock_2_relu[0][0]      \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_3 (Conv2D)  (None, 32, 32, 256)  589824      lambda_229[0][0]                 \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_3_instance  (None, 32, 32, 256)  512         R256_conv1_resblock_3[0][0]      \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_3_relu (ReL (None, 32, 32, 256)  0           R256_conv1_resblock_3_instance[0]\n","__________________________________________________________________________________________________\n","lambda_230 (Lambda)             (None, 34, 34, 256)  0           R256_conv1_resblock_3_relu[0][0] \n","__________________________________________________________________________________________________\n","R256_conv2_resblock_3 (Conv2D)  (None, 32, 32, 256)  589824      lambda_230[0][0]                 \n","__________________________________________________________________________________________________\n","R256_conv2_resblock_3_instance  (None, 32, 32, 256)  512         R256_conv2_resblock_3[0][0]      \n","__________________________________________________________________________________________________\n","add_98 (Add)                    (None, 32, 32, 256)  0           added_resblock_2_relu[0][0]      \n","                                                                 R256_conv2_resblock_3_instance[0]\n","__________________________________________________________________________________________________\n","added_resblock_3_relu (ReLU)    (None, 32, 32, 256)  0           add_98[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_231 (Lambda)             (None, 34, 34, 256)  0           added_resblock_3_relu[0][0]      \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_4 (Conv2D)  (None, 32, 32, 256)  589824      lambda_231[0][0]                 \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_4_instance  (None, 32, 32, 256)  512         R256_conv1_resblock_4[0][0]      \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_4_relu (ReL (None, 32, 32, 256)  0           R256_conv1_resblock_4_instance[0]\n","__________________________________________________________________________________________________\n","lambda_232 (Lambda)             (None, 34, 34, 256)  0           R256_conv1_resblock_4_relu[0][0] \n","__________________________________________________________________________________________________\n","R256_conv2_resblock_4 (Conv2D)  (None, 32, 32, 256)  589824      lambda_232[0][0]                 \n","__________________________________________________________________________________________________\n","R256_conv2_resblock_4_instance  (None, 32, 32, 256)  512         R256_conv2_resblock_4[0][0]      \n","__________________________________________________________________________________________________\n","add_99 (Add)                    (None, 32, 32, 256)  0           added_resblock_3_relu[0][0]      \n","                                                                 R256_conv2_resblock_4_instance[0]\n","__________________________________________________________________________________________________\n","added_resblock_4_relu (ReLU)    (None, 32, 32, 256)  0           add_99[0][0]                     \n","__________________________________________________________________________________________________\n","lambda_233 (Lambda)             (None, 34, 34, 256)  0           added_resblock_4_relu[0][0]      \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_5 (Conv2D)  (None, 32, 32, 256)  589824      lambda_233[0][0]                 \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_5_instance  (None, 32, 32, 256)  512         R256_conv1_resblock_5[0][0]      \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_5_relu (ReL (None, 32, 32, 256)  0           R256_conv1_resblock_5_instance[0]\n","__________________________________________________________________________________________________\n","lambda_234 (Lambda)             (None, 34, 34, 256)  0           R256_conv1_resblock_5_relu[0][0] \n","__________________________________________________________________________________________________\n","R256_conv2_resblock_5 (Conv2D)  (None, 32, 32, 256)  589824      lambda_234[0][0]                 \n","__________________________________________________________________________________________________\n","R256_conv2_resblock_5_instance  (None, 32, 32, 256)  512         R256_conv2_resblock_5[0][0]      \n","__________________________________________________________________________________________________\n","add_100 (Add)                   (None, 32, 32, 256)  0           added_resblock_4_relu[0][0]      \n","                                                                 R256_conv2_resblock_5_instance[0]\n","__________________________________________________________________________________________________\n","added_resblock_5_relu (ReLU)    (None, 32, 32, 256)  0           add_100[0][0]                    \n","__________________________________________________________________________________________________\n","lambda_235 (Lambda)             (None, 34, 34, 256)  0           added_resblock_5_relu[0][0]      \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_6 (Conv2D)  (None, 32, 32, 256)  589824      lambda_235[0][0]                 \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_6_instance  (None, 32, 32, 256)  512         R256_conv1_resblock_6[0][0]      \n","__________________________________________________________________________________________________\n","R256_conv1_resblock_6_relu (ReL (None, 32, 32, 256)  0           R256_conv1_resblock_6_instance[0]\n","__________________________________________________________________________________________________\n","lambda_236 (Lambda)             (None, 34, 34, 256)  0           R256_conv1_resblock_6_relu[0][0] \n","__________________________________________________________________________________________________\n","R256_conv2_resblock_6 (Conv2D)  (None, 32, 32, 256)  589824      lambda_236[0][0]                 \n","__________________________________________________________________________________________________\n","R256_conv2_resblock_6_instance  (None, 32, 32, 256)  512         R256_conv2_resblock_6[0][0]      \n","__________________________________________________________________________________________________\n","add_101 (Add)                   (None, 32, 32, 256)  0           added_resblock_5_relu[0][0]      \n","                                                                 R256_conv2_resblock_6_instance[0]\n","__________________________________________________________________________________________________\n","added_resblock_6_relu (ReLU)    (None, 32, 32, 256)  0           add_101[0][0]                    \n","__________________________________________________________________________________________________\n","u64 (Conv2DTranspose)           (None, 64, 64, 128)  294912      added_resblock_6_relu[0][0]      \n","__________________________________________________________________________________________________\n","u64_instance (InstanceNormaliza (None, 64, 64, 128)  256         u64[0][0]                        \n","__________________________________________________________________________________________________\n","u64_relu (ReLU)                 (None, 64, 64, 128)  0           u64_instance[0][0]               \n","__________________________________________________________________________________________________\n","u128 (Conv2DTranspose)          (None, 128, 128, 64) 73728       u64_relu[0][0]                   \n","__________________________________________________________________________________________________\n","u128_instance (InstanceNormaliz (None, 128, 128, 64) 128         u128[0][0]                       \n","__________________________________________________________________________________________________\n","u128_relu (ReLU)                (None, 128, 128, 64) 0           u128_instance[0][0]              \n","__________________________________________________________________________________________________\n","lambda_237 (Lambda)             (None, 134, 134, 64) 0           u128_relu[0][0]                  \n","__________________________________________________________________________________________________\n","c7s1-3 (Conv2D)                 (None, 128, 128, 1)  3137        lambda_237[0][0]                 \n","==================================================================================================\n","Total params: 7,828,865\n","Trainable params: 7,828,865\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","********************* Discriminator Architecture*********************\n","Model: \"model_24\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_52 (InputLayer)        [(None, 128, 128, 1)]     0         \n","_________________________________________________________________\n","zero_padding2d_70 (ZeroPaddi (None, 130, 130, 1)       0         \n","_________________________________________________________________\n","c64 (Conv2D)                 (None, 65, 65, 64)        1088      \n","_________________________________________________________________\n","c64_leakyrelu (LeakyReLU)    (None, 65, 65, 64)        0         \n","_________________________________________________________________\n","zero_padding2d_71 (ZeroPaddi (None, 67, 67, 64)        0         \n","_________________________________________________________________\n","c128 (Conv2D)                (None, 34, 34, 128)       131072    \n","_________________________________________________________________\n","c128_instance (InstanceNorma (None, 34, 34, 128)       256       \n","_________________________________________________________________\n","c128_leakyrelu (LeakyReLU)   (None, 34, 34, 128)       0         \n","_________________________________________________________________\n","zero_padding2d_72 (ZeroPaddi (None, 36, 36, 128)       0         \n","_________________________________________________________________\n","c256 (Conv2D)                (None, 18, 18, 256)       524288    \n","_________________________________________________________________\n","c256_instance (InstanceNorma (None, 18, 18, 256)       512       \n","_________________________________________________________________\n","c256_leakyrelu (LeakyReLU)   (None, 18, 18, 256)       0         \n","_________________________________________________________________\n","zero_padding2d_73 (ZeroPaddi (None, 20, 20, 256)       0         \n","_________________________________________________________________\n","c512 (Conv2D)                (None, 20, 20, 512)       2097152   \n","_________________________________________________________________\n","c512_instance (InstanceNorma (None, 20, 20, 512)       1024      \n","_________________________________________________________________\n","c512_leakyrelu (LeakyReLU)   (None, 20, 20, 512)       0         \n","_________________________________________________________________\n","output (Conv2D)              (None, 20, 20, 1)         8193      \n","=================================================================\n","Total params: 2,763,585\n","Trainable params: 0\n","Non-trainable params: 2,763,585\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oR0EnQILKl2E"},"source":["epochs = 50\n","batch_size = 1\n","sample_interval=1000\n","batches = int(min(train_normal.shape[0], train_infected.shape[0])/batch_size)\n","# Adversarial loss ground truths\n","valid = np.ones((batch_size,) + model.disc_patch)\n","fake = np.zeros((batch_size,) + model.disc_patch)\n","\n","fake_A_buffer = ImageBuffer(50)  # the buffer stores 50 generated images\n","fake_B_buffer = ImageBuffer(50)\n","\n","print('****************************************** Training ************************************************')\n","for epoch in range(epochs):\n","    tf.keras.backend.set_value(model.optimizer.lr, tf.keras.backend.get_value(model.optimizer.lr) *\n","                                learning_rate_decay(epoch, epochs / 2, epochs / 2))\n","\n","    if epoch == epochs // 2:\n","        print('Reduced the influence of cycle-consistency to 5, identity to 2.5')\n","        model.lambda_cycle = model.lambda_cycle // 2\n","        model.lambda_id = model.lambda_id // 2\n","\n","        model.combined.compile(loss=['mse', 'mse', 'mae', 'mae', 'mae', 'mae'], loss_weights=[1, 1, model.lambda_cycle, model.lambda_cycle, \n","                                                                                              model.lambda_id, model.lambda_id], \n","                                optimizer=model.optimizer)\n","\n","    for batch_i in range(min(len(train_infected), len(train_normal))):\n","        img_A = []\n","        img_B = []\n","        \n","        infected =  random.choice(train_infected)\n","        if np.random.random() > 0.5:\n","          infected = np.fliplr(infected)\n","        img_A.append(infected)\n","\n","        normal = random.choice(train_normal)\n","        if np.random.random() > 0.5:\n","          normal = np.fliplr(normal)\n","        img_B.append(normal)\n","        \n","        img_A = np.array(img_A).reshape(-1, 128, 128, 1)\n","        img_A = img_A/127.5 - 1\n","        img_B = np.array(img_B).reshape(-1, 128, 128, 1)\n","        img_B = img_B/127.5 - 1\n","\n","\n","        # ----------------------\n","        #  Train Discriminators\n","        # ----------------------\n","\n","        # Translate images to opposite domain\n","        fake_B = model.G_A2B.predict(img_A)\n","        fake_A = model.G_B2A.predict(img_B)\n","\n","\n","        fake_A = fake_A_buffer.query(fake_A)\n","        fake_B = fake_B_buffer.query(fake_B)\n","\n","        # Train the discriminators (original images = real / translated = Fake)\n","        dA_input = np.vstack([img_A, fake_A])\n","        dA_output = np.vstack([valid, fake])\n","        dA_loss = model.D_A.train_on_batch(dA_input, dA_output)\n","\n","        dB_input = np.vstack([img_B, fake_B])\n","        dB_output = np.vstack([valid, fake])\n","        dB_loss = model.D_B.train_on_batch(dB_input, dB_output)\n","\n","        # Total disciminator loss\n","\n","        d_loss = np.add(dA_loss, dB_loss)\n","\n","        # ------------------\n","        #  Train Generators\n","        # ------------------\n","\n","        # Train the generators\n","        g_loss = model.combined.train_on_batch([img_A, img_B],[valid, valid, img_A, img_B, img_A, img_B])\n","\n","        template = 'epoch: {}/{} | batch: {}/{} | dis_loss: {:.4f} | gen_loss: {:.4f} | adv_loss: {:.4f} | recon_loss: {:.4f} | id_loss: {:.4f}'\n","        print(template.format(epoch, epochs, batch_i, min(len(train_infected), len(train_normal)), d_loss[0], g_loss[0], np.mean(g_loss[1:3]),\n","                              np.mean(g_loss[3:5]), np.mean(g_loss[5:7])), end='\\r', flush=True)\n","\n","        # If at save interval => save generated image samples\n","        if batch_i % sample_interval == 0:\n","            sample_images(epoch, batch_i, img_A, img_B)\n","\n","    model_path = baseDir+'/saved_models/' + str(epoch)\n","    os.makedirs(model_path, exist_ok=True)\n","    model.combined.save_weights(model_path + '/combined.h5')\n","    print('\\n')\n"],"execution_count":null,"outputs":[]}]}